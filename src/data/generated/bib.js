define({ entries : {
    "hao2024secure": {
        "author": "Hao, X. and Yeoh, P. L. and She, C. and Vucetic, B. and Li, Y.",
        "doi": "10.1109/TCOMM.2023.3337376",
        "journal": "IEEE Transactions on Communications",
        "keywords": "type:Journal Article, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, resource allocation, MEC networks, security",
        "number": "3",
        "pages": "1414--1427",
        "title": "Secure deep reinforcement learning for dynamic resource allocation in wireless MEC networks",
        "type": "article",
        "volume": "72",
        "year": "2024"
    },
    "li2022cross": {
        "author": "Li, A. and Wei, X. and Wu, D. and Zhou, L.",
        "doi": "10.1109/MWC.008.2200180",
        "journal": "IEEE Wireless Communications",
        "keywords": "type:Journal Article, evaluation:Comparison with previous algorithms based on performance time, cross-modal communication, semantic communication, multi-modal systems",
        "number": "6",
        "pages": "144--151",
        "title": "Cross-modal semantic communications",
        "type": "article",
        "volume": "29",
        "year": "2022"
    },
    "saraiva2020deep": {
        "author": "Saraiva, J. V. and Braga Jr., I. M. and Monteiro, V. F. and Lima, F. R. M. and Maciel, T. F. and Freitas Jr., W. C. and Cavalcanti, F. R. P.",
        "doi": "10.48550/arXiv.2003.02643",
        "journal": "arXiv",
        "keywords": "type:Preprint, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, QoS, resource allocation, multiservice networks",
        "title": "Deep reinforcement learning for QoS-constrained resource allocation in multiservice networks",
        "type": "article",
        "year": "2020"
    },
    "tham2019deep": {
        "author": "Tham, M.-L. and Iqbal, A. and Chang, Y. C.",
        "booktitle": "2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)",
        "doi": "10.1109/APSIPAASC47483.2019.9023112",
        "keywords": "type:Conference Paper, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, resource allocation, 5G communications",
        "location": "Lanzhou, China",
        "pages": "1852--1855",
        "title": "Deep reinforcement learning for resource allocation in 5G communications",
        "type": "inproceedings",
        "year": "2019"
    },
    "vaswani2017attention": {
        "author": "Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A. N. and Kaiser, L. and Polosukhin, I.",
        "journal": "arXiv",
        "keywords": "type:Preprint, evaluation:Mathematical proofs, attention mechanisms, sequence transduction, neural machine translation",
        "note": "Accessed 16 May 2024",
        "title": "Attention is all you need",
        "type": "article",
        "url": "https://arxiv.org/abs/1706.03762",
        "year": "2017"
    },
    "wang2018deep": {
        "author": "Wang, S. and Liu, H. and Gomes, P. H. and Krishnamachari, B.",
        "doi": "10.48550/arXiv.1802.06958",
        "journal": "arXiv",
        "keywords": "type:Preprint, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, multichannel access, wireless networks",
        "title": "Deep reinforcement learning for dynamic multichannel access in wireless networks",
        "type": "article",
        "year": "2018"
    },
    "xie2021deep": {
        "author": "Xie, H. and Qin, Z. and Li, G. Y. and Juang, B.-H.",
        "doi": "10.1109/TSP.2021.3071210",
        "journal": "IEEE Transactions on Signal Processing",
        "keywords": "type:Journal Article, evaluation:Comparison with previous algorithms based on performance time, deep learning, semantic communication, signal processing",
        "pages": "2663--2675",
        "title": "Deep learning enabled semantic communication systems",
        "type": "article",
        "volume": "69",
        "year": "2021"
    },
    "xu2018experience": {
        "author": "Xu, Z. and Tang, J. and Meng, J. and Zhang, W. and Wang, Y. and Chi Harold, L. and Yang, D.",
        "doi": "10.48550/arxiv.1801.05757",
        "journal": "arXiv",
        "keywords": "type:Preprint, evaluation:Comparison with previous algorithms based on performance time, experience-driven networking, deep reinforcement learning, network optimization",
        "title": "Experience-driven networking: A deep reinforcement learning based approach",
        "type": "article",
        "year": "2018"
    },
    "zhang2023drl": {
        "author": "Zhang, H. and Wang, H. and Li, Y. and Long, K. and Nallanathan, A.",
        "doi": "10.1109/TCOMM.2023.3274145",
        "journal": "IEEE Transactions on Communications",
        "keywords": "type:Journal Article, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, dynamic resource allocation, semantic communication",
        "number": "7",
        "pages": "3992--4004",
        "title": "DRL-driven dynamic resource allocation for task-oriented semantic communication",
        "type": "article",
        "volume": "71",
        "year": "2023"
    },
    "zhi2021deep": {
        "author": "Zhi, Y. and Tian, J. and Deng, X. and Qiao, J. and Lu, D.",
        "doi": "10.1016/j.dcan.2021.09.013",
        "journal": "Digital Communications and Networks",
        "keywords": "type:Journal Article, evaluation:Comparison with previous algorithms based on performance time, deep reinforcement learning, resource allocation, D2D communications, heterogeneous networks",
        "title": "Deep reinforcement learning-based resource allocation for D2D communications in heterogeneous cellular networks",
        "type": "article",
        "year": "2021"
    }
}});